<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
               "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head><!-- <meta name="baidu-site-verification" content="707024a76f8f40b549f07f478abab237"/> -->
<title>In-Stream Big Data Processing</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<meta name="title" content="In-Stream Big Data Processing"/>
<meta name="generator" content="Org-mode"/>
<meta name="generated" content="2013-09-05 09:53:17 CST"/>
<meta name="author" content="dirtysalt"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  html { font-family: Times, serif; font-size: 12pt; }
  .title  { text-align: center; }
  .todo   { color: red; }
  .done   { color: green; }
  .tag    { background-color: #add8e6; font-weight:normal }
  .target { }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  {margin-left:auto; margin-right:0px;  text-align:right;}
  .left   {margin-left:0px;  margin-right:auto; text-align:left;}
  .center {margin-left:auto; margin-right:auto; text-align:center;}
  p.verse { margin-left: 3% }
  pre {
	border: 1pt solid #AEBDCC;
	background-color: #F3F5F7;
	padding: 5pt;
	font-family: courier, monospace;
        font-size: 90%;
        overflow:auto;
  }
  table { border-collapse: collapse; }
  td, th { vertical-align: top;  }
  th.right  { text-align:center;  }
  th.left   { text-align:center;   }
  th.center { text-align:center; }
  td.right  { text-align:right;  }
  td.left   { text-align:left;   }
  td.center { text-align:center; }
  dt { font-weight: bold; }
  div.figure { padding: 0.5em; }
  div.figure p { text-align: center; }
  div.inlinetask {
    padding:10px;
    border:2px solid gray;
    margin:10px;
    background: #ffffcc;
  }
  textarea { overflow-x: auto; }
  .linenr { font-size:smaller }
  .code-highlighted {background-color:#ffff00;}
  .org-info-js_info-navigation { border-style:none; }
  #org-info-js_console-label { font-size:10px; font-weight:bold;
                               white-space:nowrap; }
  .org-info-js_search-highlight {background-color:#ffff00; color:#000000;
                                 font-weight:bold; }
  /*]]>*/-->
</style><link rel="stylesheet" type="text/css" href="./css/site-plain.css" />
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>

</head>
<body><!-- <div id="bdshare" class="bdshare_t bds_tools_32 get-codes-bdshare"><a class="bds_tsina"></a><span class="bds_more"></span><a class="shareCount"></a></div> --><!-- Place this tag where you want the +1 button to render --><g:plusone annotation="inline"></g:plusone>


<div id="content">
<h1 class="title">In-Stream Big Data Processing</h1>


<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1 in-stream-big-data-process</a>
<ul>
<li><a href="#sec-1-1">1.1 Basics of Distributed Query Processing</a>
<ul>
<li><a href="#sec-1-1-1">1.1.1 Partitioning and Shuffling</a></li>
<li><a href="#sec-1-1-2">1.1.2 Pipelining</a></li>
</ul>
</li>
<li><a href="#sec-1-2">1.2 In-Stream Processing Patterns</a>
<ul>
<li><a href="#sec-1-2-1">1.2.1 Stream Replay</a></li>
<li><a href="#sec-1-2-2">1.2.2 Lineage Tracking</a></li>
<li><a href="#sec-1-2-3">1.2.3 State Checkpointing</a></li>
<li><a href="#sec-1-2-4">1.2.4 Additive State and Sketches</a></li>
<li><a href="#sec-1-2-5">1.2.5 Logical Time Tracking</a></li>
<li><a href="#sec-1-2-6">1.2.6 Aggregation in a Persistent Store</a></li>
<li><a href="#sec-1-2-7">1.2.7 Aggregation on a Sliding Window</a></li>
</ul>
</li>
<li><a href="#sec-1-3">1.3 Query Processing Pipeline: Storm, Cassandra, Kafka</a></li>
<li><a href="#sec-1-4">1.4 Towards Unified Big Data Processing</a></li>
<li><a href="#sec-1-5">1.5 References</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> in-stream-big-data-process</h2>
<div class="outline-text-2" id="text-1">


<p>
<a href="http://highlyscalable.wordpress.com/2013/08/20/in-stream-big-data-processing/">http://highlyscalable.wordpress.com/2013/08/20/in-stream-big-data-processing/</a>
</p>
<p>
In recent years, this idea got a lot of traction and a whole bunch of solutions like <b>Twitter’s Storm,  Yahoo’s S4, Cloudera’s Impala, Apache Spark, and Apache Tez</b> appeared and joined the army of Big Data and NoSQL systems. This article is an effort to 
</p><ul>
<li>explore techniques used by developers of in-stream data processing systems,
</li>
<li>trace the connections of these techniques to massive batch processing and OLTP/OLAP databases,
</li>
<li>and discuss how one unified query engine can support in-stream, batch, and OLAP processing at the same time.
</li>
</ul>


<p>
At Grid Dynamics, we recently faced a necessity to build an in-stream data processing system that aimed to crunch about 8 billion events daily providing fault-tolerance and strict transactioanlity i.e. none of these events can be lost or duplicated. This system has been designed to supplement and succeed the existing Hadoop-based system that had too high latency of data processing and too high maintenance costs.（使用Hadoop系统来处理数据会产生比较高的延迟，是流式系统出现的重要原因） A high-level overview of the environment we worked with is shown in the figure below:
</p>
<p>
<img src="./images/in-stream-big-data-processing-arch.png"  alt="./images/in-stream-big-data-processing-arch.png" />
</p>
<p>
Our goal was to equip all facilities with a new in-stream engine (shown in the bottom of the figure) that processes most intensive data flows and ships the pre-aggregated data to the central facility, thus decreasing the amount of raw data and heavy batch jobs in Hadoop. The design of the in-stream processing engine itself was driven by the following requirements: 流式处理系统通常比较重要的特征是：
</p><ul>
<li>SQL-like functionality. The engine has to evaluate SQL-like queries continuously, including joins over time windows and different aggregation functions that implement quite complex custom business logic. The engine can also involve relatively static data (admixtures) loaded from the stores of Aggregated Data. Complex multi-pass data mining algorithms are beyond the immediate goals. （使用SQL的方式来处理多个时间窗口的数据，并且这个处理是持续的）
</li>
<li>Modularity and flexibility. It is not to say that one can simply issue a SQL-like query and the corresponding pipeline will be created and deployed automatically, but it should be relatively easy to assemble quite complex data processing chains by linking one block to another.（模块化和灵活性，这样能够组织成为更加复杂的查询）
</li>
<li>Fault-tolerance. Strict fault-tolerance is a principal requirement for the engine. As it sketched in the bottom part of the figure, one possible design of the engine is to use distributed data processing pipelines that implement operations like joins and aggregations or chains of such operations, and connect these pipelines by means of fault-tolerant persistent buffers. These buffers also improve modularity of the system by enabling publish/subscribe communication style and easy addition/removal of the pipelines. The pipelines can be stateful and the engine’s middleware should provide a persistent storage to enable state checkpointing. All these topics will be discussed in the later sections of the article.（pipeline之间使用buffer来进行持久化来解决容错问题）
</li>
<li>Interoperability with Hadoop. The engine should be able to ingest both streaming data and data from Hadoop i.e. serve as a custom query engine atop of HDFS.（和HDFS做交互）
</li>
<li>High performance and mobility. The system should deliver performance of tens of thousands messages per second even on clusters of minimal size. The engine should be compact and efficient, so one can deploy it in multiple datacenters on small clusters.（在小规模集群上处理到w级别的QPS，并且容易部署） <b>NOTE（dirlt）：部署和可维护性其实在很大程度上需要考虑</b>
</li>
</ul>



</div>

<div id="outline-container-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> Basics of Distributed Query Processing</h3>
<div class="outline-text-3" id="text-1-1">

<p>It is clear that distributed in-stream data processing has something to do with query processing in distributed relational databases. Many standard query processing techniques can be employed by in-stream processing engine, so it is extremely useful to understand classical algorithms of distributed query processing and see how it all relates to in-stream processing and other popular paradigms like MapReduce.
</p>

</div>

<div id="outline-container-1-1-1" class="outline-4">
<h4 id="sec-1-1-1"><span class="section-number-4">1.1.1</span> Partitioning and Shuffling</h4>
<div class="outline-text-4" id="text-1-1-1">

<p>Although optimal partitioning for selection and projection operations can be tricky (e.g. for range queries),  <b>we can assume that for in-stream data filtering it is practically enough to distribute data among the processors using a hash-based partitioning.</b>
</p>
<p>
Processing of distributed joins is not so easy and requires a more thorough examination. There are two main data partitioning techniques that can be employed by distributed join processing:
</p><ul>
<li>Disjoint data partitioning
</li>
<li>Divide and broadcast join
</li>
</ul>

<p>In a distributed database, division typically is not a part of the query processing itself because data sets are initially distributed among multiple nodes.
</p>
<p>
Disjoint data partitioning technique shuffles the data into several partitions in such a way that join keys in different partitions do not overlap.
</p>
<p>
<img src="./images/in-stream-disjoint-data-partitioning.png"  alt="./images/in-stream-disjoint-data-partitioning.png" />
</p>
<p>
The divide and broadcast join algorithm is illustrated in the figure below. This method divides the first data set into multiple disjoint partitions (R1, R2, and R3 in the figure) and replicates the second data set to all processors. 
</p>
<p>
<img src="./images/in-stream-divide-and-broadcast-join.png"  alt="./images/in-stream-divide-and-broadcast-join.png" />
</p>
</div>

</div>

<div id="outline-container-1-1-2" class="outline-4">
<h4 id="sec-1-1-2"><span class="section-number-4">1.1.2</span> Pipelining</h4>
<div class="outline-text-4" id="text-1-1-2">

<p>all operators in a query should be chained in such a way that the data flows smoothly through the entire pipeline i.e. neither operation should block processing by waiting for a large piece of input data without producing any output or by writing intermediate results
on disk.  <b>Some operations like sorting are inherently incompatible with this concept (obviously, a sorting block cannot produce any output until the entire input is ingested), but in many cases pipelining algorithms are applicable.</b> （虽然一些算法需要等待到全量数据到达，但是大部分算法还是可以in-stream处理的。对于这类需要全量数据的算法其实应该考虑提供时间窗口，比如10s内数据作为一个batch来处理这样，maybe） A typical example of pipelining is shown below: （下面以hash join为例）
</p>
<p>
<img src="./images/in-stream-simple-hash-join.png"  alt="./images/in-stream-simple-hash-join.png" />
</p>
<p>
In-stream processing naturally employs this technique to join a data stream with the static data (admixtures). <b>但是上面这种方式通常是和静态数据来做join的。</b>
</p>
<p>
In relational databases, join operation can take advantage of pipelining by using the symmetric hash join algorithm or some of its advanced variants. Symmetric hash join is a generalization of hash join. Whereas a normal hash join requires at least one of its inputs to be completely available to produce first results (the input is needed to build a hash table), symmetric hash join is able to produce first results immediately. In contrast to the normal hash join, it maintains hash tables for both inputs and populates these tables as tuples arrive: 
</p>
<p>
<img src="./images/in-stream-symmetric-hash-join.png"  alt="./images/in-stream-symmetric-hash-join.png" />
</p>
<p>
As a tuple comes in, the joiner first looks it up in the hash table of the other stream. If match is found, an output tuple is produced. Then the tuple is inserted in its own hash table. However, it does not make a lot of sense to perform a complete join of infinite streams. In many cases join is performed on a finite time window or other type of buffer e.g. LFU cache that contains most frequent tuples in the stream. <b>Symmetric hash join can be employed if the buffer is large comparing to the stream rate or buffer is flushed frequently according to some application logic or buffer eviction strategy is not predictable.</b> （sym hash join有一定的限制，依然没有获得全量的数据，但是如果每次到达的数据足够多的话，那么实际上这种方法还是可行的。这里的Hash数据也是需要不断evict的）
</p>
<p>
<b>It is worth noting that in-stream processing often deals with sophisticated stream correlation algorithms where records are matched based on scoring metrics, not on field equality condition. A more complex system of buffers can be required for both streams in such cases.</b> （在online或者是in-stream上面算法相对都比较fancy）
</p>
</div>
</div>

</div>

<div id="outline-container-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> In-Stream Processing Patterns</h3>
<div class="outline-text-3" id="text-1-2">


</div>

<div id="outline-container-1-2-1" class="outline-4">
<h4 id="sec-1-2-1"><span class="section-number-4">1.2.1</span> Stream Replay</h4>
<div class="outline-text-4" id="text-1-2-1">

</div>

</div>

<div id="outline-container-1-2-2" class="outline-4">
<h4 id="sec-1-2-2"><span class="section-number-4">1.2.2</span> Lineage Tracking</h4>
<div class="outline-text-4" id="text-1-2-2">

</div>

</div>

<div id="outline-container-1-2-3" class="outline-4">
<h4 id="sec-1-2-3"><span class="section-number-4">1.2.3</span> State Checkpointing</h4>
<div class="outline-text-4" id="text-1-2-3">

</div>

</div>

<div id="outline-container-1-2-4" class="outline-4">
<h4 id="sec-1-2-4"><span class="section-number-4">1.2.4</span> Additive State and Sketches</h4>
<div class="outline-text-4" id="text-1-2-4">

</div>

</div>

<div id="outline-container-1-2-5" class="outline-4">
<h4 id="sec-1-2-5"><span class="section-number-4">1.2.5</span> Logical Time Tracking</h4>
<div class="outline-text-4" id="text-1-2-5">

</div>

</div>

<div id="outline-container-1-2-6" class="outline-4">
<h4 id="sec-1-2-6"><span class="section-number-4">1.2.6</span> Aggregation in a Persistent Store</h4>
<div class="outline-text-4" id="text-1-2-6">

</div>

</div>

<div id="outline-container-1-2-7" class="outline-4">
<h4 id="sec-1-2-7"><span class="section-number-4">1.2.7</span> Aggregation on a Sliding Window</h4>
<div class="outline-text-4" id="text-1-2-7">

</div>
</div>

</div>

<div id="outline-container-1-3" class="outline-3">
<h3 id="sec-1-3"><span class="section-number-3">1.3</span> Query Processing Pipeline: Storm, Cassandra, Kafka</h3>
<div class="outline-text-3" id="text-1-3">

</div>

</div>

<div id="outline-container-1-4" class="outline-3">
<h3 id="sec-1-4"><span class="section-number-3">1.4</span> Towards Unified Big Data Processing</h3>
<div class="outline-text-3" id="text-1-4">

</div>

</div>

<div id="outline-container-1-5" class="outline-3">
<h3 id="sec-1-5"><span class="section-number-3">1.5</span> References</h3>
<div class="outline-text-3" id="text-1-5">

<ul>
<li>A. Wilschut and P. Apers, “Dataflow Query Execution in a Parallel Main-Memory Environment “
</li>
<li>T. Urhan and M. Franklin, “XJoin: A Reactively-Scheduled Pipelined Join Operator“
</li>
<li>M. Zaharia, T. Das, H. Li, S. Shenker, and I. Stoica, “Discretized Streams: An Efficient and Fault-Tolerant Model for Stream Processing on Large Clusters”
</li>
<li>E. Jacobsen and R. Lyons, “The Sliding DFT“
</li>
<li>A. Elmagarmid, Data Streams Models and Algorithms
</li>
<li>N. Marz, “Big Data Lambda Architecture”
</li>
<li>J. Kinley, “The Lambda architecture: principles for architecting realtime Big Data systems”
</li>
<li><a href="http://hortonworks.com/hadoop/tez/">http://hortonworks.com/hadoop/tez/</a>
</li>
<li><a href="http://hortonworks.com/stinger/">http://hortonworks.com/stinger/</a>
</li>
<li><a href="http://spark-project.org/">http://spark-project.org/</a>
</li>
</ul>


</div>
</div>
</div>
</div>

<!-- Baidu Analytics BEGIN --><script type="text/javascript">var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F54a700ad7035f6e485eaf2300641e7e9' type='text/javascript'%3E%3C/script%3E"));</script><!-- Baidu Analytics END --><!-- Google Analytics BEGIN --><script type="text/javascript">  var _gaq = _gaq || [];  _gaq.push(['_setAccount', 'UA-31377772-1']);  _gaq.push(['_trackPageview']);  (function() {    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);  })();</script><!-- Google Analytics END --><!-- Baidu Button BEGIN --><!-- <script type="text/javascript" id="bdshare_js" data="type=tools&amp;uid=6762177" ></script><script type="text/javascript" id="bdshell_js"></script><script type="text/javascript"> document.getElementById("bdshell_js").src = "http://bdimg.share.baidu.com/static/js/shell_v2.js?cdnversion=" + Math.ceil(new Date()/3600000)</script> --><!-- Baidu Button END --><!-- G+ BEGIN --><!-- Place this render call where appropriate --><script type="text/javascript">  (function() {    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;    po.src = 'https://apis.google.com/js/plusone.js';    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);  })();</script><!-- G+ END --><!-- DISQUS BEGIN --><div id="disqus_thread"></div><script type="text/javascript">/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * *//* required: replace example with your forum shortname  */var disqus_shortname = 'dirlt';var disqus_identifier = 'in-stream-big-data-process.html';var disqus_title = 'in-stream-big-data-process.html';var disqus_url = 'http://dirlt.com/in-stream-big-data-process.html';/* * * DON'T EDIT BELOW THIS LINE * * */(function() {var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a><!-- DISQUS END --></body>
</html>
