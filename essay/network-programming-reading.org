* network-programming-reading
#+OPTIONS: H:4

** network programming issue
*** timeout and retry
超时(timeout)通常是client访问server提供的网络服务所能容忍的时间上限，因为网络服务可能存在诸多的可变性(variability), 而解决网络服务可变性一种常用办法就是重试(retry). 

--------------------
retry可以是服务内部进行retry，也可以是由client发起retry，但是通常服务内部发起retry的代价相比client发起retry的代价要小，这点非常好理解。假设一个访问数据库的服务，逻辑通常是
   1. 接收client请求
   2. 解析client请求
   3. 连接数据库后端
   4. 向数据库转发client请求
   5. 从数据库接收请求数据
   6. 将请求数据打包为client响应
   7. 发送client响应
可能中间还存在cache等操作但是这里不考虑。其中3，4，5涉及到和数据库网络交互，1，7涉及到和client网络交互，而2，6则主要是CPU计算。就耗时情况来说，其中2，6相比3，4，5几率会更小，超时主要原因主要是集中在访问后端数据库上。如果请求4出现超时的话，那么server内部retry和client发起retry的逻辑分别是
   - server retry：重新起3，4
   - client retry：重新发起1，2，3，4
也就是说client retry比server retry多出了两个步骤，花费时间更长。所以相对client external retry, server internal retry效率更高。

--------------------
如果选定server internal retry这种方案的话，那么就需要考虑本次请求timeout的时间应该来如何分配在逻辑各个环节中。以上面逻辑为例：
   - 我们忽略1，7最后面这两段的时间，因为这个部分时间和我们如何重试没有关系，我们可以设置一个定值比如内网2ms
   - 2，6也不考虑因为可以假设这个过程很快，我们也可以设置一个定制比如2ms
   - 如果我们考虑长链接的话，3之需要获取建立好的链接即可，这个时间就可以不考虑。
 所以timeout分配主要是在4，5两个阶段，也就是请求一次数据库的时间。

假设分配时间是300ms，允许请求3次，一种比较简单的办法是平均分，三次各100ms。但是这样存在一个问题就是，比如数据库服务响应时间分布如下
   - p50 = 2ms
   - p90 = 8ms
   - p96 = 100ms
   - p99 = 140ms
那么这种时间分配的话只能满足p96的需求。而如果按照指数分布请求的话，2ms，8ms，16ms，32ms，142ms，那么响应p99的几率就可以增大很多。

--------------------
下面是一段在FastHBaseRest里面分配timeout的代码
#+BEGIN_SRC Java
    private long calcRequestTimeout(int retryTime, int qualifierCount) {
        final long kCPUReservedTimeSlice = 10; // allocate 10ms for CPU.
        if (qualifierCount == 0) {
            retryTime += 7;
            if (retryTime > 13) {
                retryTime = 13;
            }
            // 128ms .. 8192ms
        } else if (qualifierCount > 64) {
            retryTime += 5;
            if (retryTime > 12) {
                retryTime = 12;
            }
            // 32ms .. 4096ms.
        } else {
            retryTime += 3;
            if (retryTime > 10) {
                retryTime = 10;
            }
            // 8ms .. 1024ms.
        }
        long base = 1 << retryTime;
        if ((requestTimeout - kCPUReservedTimeSlice) > base) {
            return base;
        } else {
            return 0;
        }
    }
#+END_SRC
   - 其中10ms用于CPU与额外开销
   - qualifierCount表示请求hbase的column数目，
     - 如果==0的话表示请求column family, 那么超时时间分别是128ms, 256ms, ... 8192ms
     - 如果>64的哈表示请求column但是字段很多，所以超时时间分配是32ms, 64ms, ... 4096ms
     - 其他情况可以认为hbase返回很快，所以超时时间分配是8ms, 16ms, ... 1024ms

*** connection pool implementation
connection pool实现上有下面几点考虑
   1. 连接一旦连上就不要断开，因为建立连接开销非常大，所以最好不要轻易销毁。
   2. 为了防止单机上连接数目过多，需要设置连接数目上限。
   3. 后端节点可能会挂掉，我们需要能够检查出这种情况出来，减少上面的连接数目。
   4. 后端节点也可能会逐渐恢复，所以也要能够检查这种情况出来，平衡后端服务器负载。
   5. 对后端节点请求需要确保负载均衡，除非节点宕机，否则节点之间的压力应该是均匀的。
dmp service在实现上综合了这些考虑，在ProxyConnector里面是connection pool的实现

--------------------
后端节点的数据结构如下
#+BEGIN_SRC Java
public static class Node {
        InetSocketAddress socketAddress;
        ClientBootstrap bootstrap;
        BlockingQueue<ProxyHandler> pool;
        AtomicInteger connectionNumber = new AtomicInteger(0);
        int punishCount;
        static final int kPunishThreshold = 10;
    }
#+END_SRC
   - socketAddress 后端地址 
   - bootstrap netty框架
   - pool 表示和这个节点上相连可用的连接池。需要说明的是这个连接也可能是作废的，因为如果节点重启的话那么这个连接失效。失效检测是在发起请求的时候才会触发。
   - connectionNumber 和这个节点建立了多少个连接。
   - punishCount 过去一段时间内没有连接成功或者是读写超时断开的次数，这个指标用于监控节点服务是否OK
   - kPunishThreshold punishCount的上限，超过一定次数之后不会往上加，不然恢复就会非常慢。

--------------------
获取连接的代码如下
#+BEGIN_SRC Java
    public ProxyHandler acquireConnection() {
        int id = rrId;
        rrId = (rrId + 1) % aNodes.length;
        boolean sleep = false;
        for (int i = 0; i < aNodes.length; i++) {
            int idx = (id + i) % aNodes.length;
            Node node = aNodes[idx];
            if (node.punishCount >= (Node.kPunishThreshold - 2)) {
                continue;
            }
            try {
                sleep = true;
                int retry = 3;
                while (retry > 0) {
                    ProxyHandler handler = node.pool.poll(configuration.getProxyConnectTimeout(), TimeUnit.MILLISECONDS);
                    if (handler == null) {
                        VeritasServer.logger.debug("proxy connector acquire connection timeout");
                        connect(node);
                    } else {
                        VeritasServer.logger.debug("proxy connector acquire connection OK!");
                        return handler;
                    }
                    retry--;
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
                // pass.
            }
        }
        if (!sleep) {
            // if we turn around and find no connection available, we have to wait.
            try {
                Thread.sleep(configuration.getProxyConnectTimeout());
            } catch (Exception e) {
                e.printStackTrace();
                // pass.
            }
        }
        return null;
    }

    public void releaseConnection(ProxyHandler handler) {
        try {
            VeritasServer.logger.debug("proxy connector release connection");
            handler.node.pool.put(handler);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
#+END_SRC
   1. rrId是一个静态变量，相当于每次调用acquireConnection的时候都以round-robin的方式从某个node开始挑选
   2. 一轮会检查所以的节点可用情况，挑选一个可用节点上的连接出来。 *这样来达到大致的负载均衡*
   3. 如果过去一段时间连接失败次数过多的话，那么就不考虑从这个节点的链接。这里-2是考虑到很可能这个时候节点已经开始恢复了，但是恢复比较慢，所以可以考虑考虑这个节点了。
   4. 然后在某个节点上尝试3次从队列里面获取，获取时间是connectTimeout. 这个考虑是如果没有的话，那么就发起连接。如果连接正常的话，那么下次就一定可以获取到连接。如果连续发起两个连接依然没有获得的话，那么可能这个节点可能失效了或者说当前连接数目都用满了，就会放弃。
   5. 在步骤4这里有过一些等待时间，所以将sleep = true. 这里sleep主要是为了防止一个情况，假设所有节点失效，外部过于频繁地调用acquireConnection, 那么非常耗CPU，所以如果在一轮里面检测到所有节点失效的话，那么就会等待一段时间。

--------------------
节点建立连接和关闭过程如下
#+BEGIN_SRC Java
    public void channelConnected(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception {
        VeritasServer.logger.debug("proxy channel connected");
        channel = e.getChannel();
        channel.setReadable(false);
        context = ctx;
        node.punishCount -= 1;
        proxyConnector.releaseConnection(this);
    }

    public void onChannelClosed(Channel channel, final Node node) {
        // connection closed.
        VeritasServer.logger.debug("connector on channel closed end");
        connectionNumber.decrementAndGet();
        node.connectionNumber.decrementAndGet();
        node.punishCount += 1;
        if (node.punishCount >= Node.kPunishThreshold) {
            node.punishCount = Node.kPunishThreshold;
        }
        AsyncClient.timer.newTimeout(new TimerTask() {
            @Override
            public void run(Timeout timeout) throws Exception {
                ProxyConnector.getInstance().connect(node);
            }
        }, configuration.getProxyConnectTimeout() * (1 << node.punishCount), TimeUnit.MILLISECONDS);
    }

    public void connect(Node node) {
        // if connection number on this node got threshold.
        if (node.connectionNumber.get() < configuration.getProxyConnectionNumberPerNode()) {
            connectionNumber.incrementAndGet();
            node.connectionNumber.incrementAndGet();
            node.bootstrap.connect(node.socketAddress);
        }
    }
#+END_SRC
    - channelConnected是在连接建立OK的时候调用，这时候punishCount -= 1
    - onChannelClosed是在连接关闭的时候调用。通常连接是不关闭的，如果关闭肯定是因为连接不上或者是读写异常造成的，那么需要以 (1 << node.punishCount) * connectTimeout 作为指数退避来等待重新建立连接，不然如果节点挂掉的话，就会出现频繁请求连接而又不能够成功。因为punishCount上线是10, connecTimeout = 10ms, 所以等待最长时间就是10s，这一般是人工恢复时间间隔。
    - connect是发起连接的操作，这里判断了连接数目的上限。

--------------------
*然后还有一个问题就是如何解决后端链接失效的问题* 。后端失效的问题是这样产生的，假设服务A需要访问服务B，所以开辟了很多和B的链接。之后B重启了服务，那么之前A缓存的所有链接都失效了。一个办法是定时去检查这些链接是否失效，如果失效的话，那么就直接丢弃并且建立新的链接。另外一种办法就是在访问的时候进行判断，如果对端关闭的话，那么在write的时候就会出现pipe broken/CloeedChannelException这样的问题，而这个过程触发是非常快的。 *注意我们没有使用访问前先检查链接是否正常的方式来工作，是因为对于大部分链接来说平时是不会断开的，每次访问之前都要重新检查链接这个过程是没有意义的* 如果出现后端链接失效的话，可以认为和访问超时逻辑一样，丢弃链接之后发起重试，这样在很短的时间就可以基本上将所有的失效链接全部检查出来并且丢弃。

#+BEGIN_SRC Java
    public void handleProxyRequestId() {
        if (retryProxyId == 0) {
            requestProxyIdTimestamp = System.currentTimeMillis();
        }
        // check timeout.
        long timeout = calcRequestTimeout(retryProxyId);
        if (timeout < 0) {
            raiseException("detect timeout in request proxy id");
            return;
        }
        // build request.
        // ...
        // obtain connection.
        ProxyHandler handler = null;
        while (true) {
            handler = ProxyConnector.getInstance().acquireConnection();
            if (handler == null) {
                if (calcRequestTimeout(retryProxyId) < 0) {
                    raiseException("detect timeout in request proxy id");
                    return;
                }
            } else {
                break;
            }
        }
        // write it out.
        // ...
    }

    public void handleProxyResponseId() {
         // check proxy channel closed.
        if (proxyChannelClosed) {
            proxyChannelClosed = false;
            retryProxyId += 1;
            code = Status.kProxyRequestId;
            run();
            return;
        }
#+END_SRC

*** when async is better than sync
什么时候异步比同步好？ 先来看看同步处理网络请求的方式
   - accept接收请求获得fd
   - 开辟线程（池）来处理fd
   - 处理fd存在read/write fd操作以及CPU操作

file:./images/network-sync-handler.png

如果read/write fd操作非常快的话，那么阴影部分也就是CPU部分比例就相对更多，瓶颈就在CPU上，这种情况非常适合同步。说白了就是CPU密集型的计算。可是通常来说，大部分互联网服务即使是在内网服务也不一定是CPU密集型计算。比如一个分配uniq id的服务，可能网络时间在1ms，而CPU时间也在1ms左右，那么网络传输时间相当占据50%。如果在外网这种情况更加明显，比如通过手机访问服务的话，传输时间可能就在秒级别，而CPU处理时间在ms级别。也就是说大部分互联网服务，相对CPU计算相比，网路传输时间还是非常长的。

以外网服务为例，假设网络传输占用500ms，CPU处理时间在10ms，以同步方式处理的话，1个线程每秒处理2个请求，如果线程池是1k的话，那么QPS峰值也就是2k。然后问题是我们是否可以通过开高线程数目来解决并发问题呢？比如线程数目开到1w？这样如果CPU不是瓶颈的话，那么QPS就能达到2w. *这种方式实际上就是通过线程来支撑并发。* 但是线程数目实际上会受到上下文切换(context switch)限制，因为线程数目越多，上下文切换开销代价越大，消耗额外的CPU时间越长。理论上通过减少上下文切换开销，就可以以允许开更多的执行单元。历史上有过这样的做法，就是从进程到线程，历史还在延续，那就是从线程到纤程(fiber)/协程(coroutine). 这是一个思路，只是现在这样的做法以及框架还不够多。Akka，Erlang算是几个。 *TODO(dirlt):write a benchmark to verify context switch as bottlenect*

--------------------
上面的问题在于，通过在执行单元上检查fd是否可以读写，这样一个fd需要分配一个执行单元。如果有这样一个组件，可以在一个执行单元里面有效地检测多个fd上面是否可读可写，那么就可以不通过开辟更多的执行单元来支撑更多的fd。这个组件就是多路复用，实现有select/kqueue/epoll. 通过epoll可以在一个执行单元里面有效地管理多个fd. 如果使用epoll的话，那么上面请求方式就变成如下：

file:./images/network-async-handler.png

这种情况下epoll组件完成了检测fd是否可以读写的事情，执行单元则只做CPU方面的工作。因为epoll可以有效地检测众多fd上面可读可写，所以就没有必要通过靠执行单元来支撑并发数量了。 *对于执行单元来说，不再是自己去同步等待fd上的数据到达，而是让将等待fd数据到达交给epoll这个组件去完成，等epoll发现fd上面可读或者是可写的时候，在返回和通知执行单元可以操作这个fd.这种方式就是异步*

